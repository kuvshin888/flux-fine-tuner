# –î–æ–æ–±—É—á–µ–Ω–∏–µ –≥–æ—Ç–æ–≤—ã—Ö LoRA –≤ FLUX Fine-Tuner

–¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –¥–æ–æ–±—É—á–∞—Ç—å —É–∂–µ –≥–æ—Ç–æ–≤—ã–µ LoRA –≤–º–µ—Å—Ç–æ —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤—ã—Ö —Å –Ω—É–ª—è! –≠—Ç–æ –ø–æ–ª–µ–∑–Ω–æ –¥–ª—è:

- üé® **–£–ª—É—á—à–µ–Ω–∏—è –Ω–µ–¥–æ–æ–±—É—á–µ–Ω–Ω—ã—Ö LoRA** - –¥–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ —à–∞–≥–æ–≤ –æ–±—É—á–µ–Ω–∏—è
- üîÑ **–ê–¥–∞–ø—Ç–∞—Ü–∏–∏ –ø–æ–¥ –Ω–æ–≤—ã–µ —Å—Ç–∏–ª–∏** - –≤–æ–∑—å–º–∏—Ç–µ –ø–æ—Ä—Ç—Ä–µ—Ç–Ω—É—é LoRA –∏ –¥–æ–æ–±—É—á–∏—Ç–µ –Ω–∞ –ø–µ–π–∑–∞–∂–∞—Ö  
- üéØ **–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤** - —Å–º–µ—à–∞–π—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç–∏–ª–µ–π –≤ –æ–¥–Ω–æ–π LoRA
- ‚ö° **–≠–∫–æ–Ω–æ–º–∏–∏ –≤—Ä–µ–º–µ–Ω–∏** - –Ω–µ –Ω–∞—á–∏–Ω–∞–π—Ç–µ –æ–±—É—á–µ–Ω–∏–µ —Å –Ω—É–ª—è

## –ù–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

### `pretrained_lora_url`
URL –≥–æ—Ç–æ–≤–æ–π LoRA –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç HuggingFace URLs –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
```
https://huggingface.co/user/model/resolve/main/lora.safetensors
```

**–ü—Ä–∏–º–µ—Ä:**
```
https://huggingface.co/fofr/flux-80s-cyberpunk/resolve/main/lora.safetensors
```

### `keep_optimizer_for_resume` 
–°–æ—Ö—Ä–∞–Ω–∏—Ç—å `optimizer.pt` —Ñ–∞–π–ª –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –±—É–¥—É—â–µ–≥–æ –¥–æ–æ–±—É—á–µ–Ω–∏—è.
- `true` - —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å optimizer –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è
- `false` (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é) - —É–¥–∞–ª–∏—Ç—å optimizer –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –º–µ—Å—Ç–∞

## –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ë–∞–∑–æ–≤–æ–µ –¥–æ–æ–±—É—á–µ–Ω–∏–µ
```bash
# –î–æ–æ–±—É—á–∏—Ç—å –≥–æ—Ç–æ–≤—É—é LoRA –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
python train.py \
  --input_images="my_new_images.zip" \
  --pretrained_lora_url="https://huggingface.co/user/model/resolve/main/lora.safetensors" \
  --trigger_word="NEWSTYLE" \
  --steps=500 \
  --learning_rate=2e-4
```

### –£–ª—É—á—à–µ–Ω–∏–µ –Ω–µ–¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π LoRA
```bash
# –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ –Ω–µ–¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π LoRA
python train.py \
  --input_images="original_dataset.zip" \
  --pretrained_lora_url="https://huggingface.co/myuser/underfitted-lora/resolve/main/lora.safetensors" \
  --trigger_word="SAMESTYLE" \
  --steps=1000 \
  --learning_rate=1e-4 \
  --keep_optimizer_for_resume=true
```

### –ê–¥–∞–ø—Ç–∞—Ü–∏—è —Å—Ç–∏–ª—è
```bash
# –í–∑—è—Ç—å –ø–æ—Ä—Ç—Ä–µ—Ç–Ω—É—é LoRA –∏ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥ –ø–µ–π–∑–∞–∂–∏
python train.py \
  --input_images="landscape_photos.zip" \
  --pretrained_lora_url="https://huggingface.co/portraits/amazing-portraits/resolve/main/lora.safetensors" \
  --trigger_word="LANDSCP" \
  --steps=800 \
  --learning_rate=3e-4
```

## –õ–æ–≥–∏ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

–ü—Ä–∏ –¥–æ–æ–±—É—á–µ–Ω–∏–∏ LoRA –≤—ã —É–≤–∏–¥–∏—Ç–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –ª–æ–≥–∏:

```
üîÑ –†–µ–∂–∏–º –¥–æ–æ–±—É—á–µ–Ω–∏—è –≥–æ—Ç–æ–≤–æ–π LoRA –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω
Downloading pretrained LoRA from: https://huggingface.co/user/model/resolve/main/lora.safetensors
‚úÖ –ì–æ—Ç–æ–≤–∞—è LoRA –∑–∞–≥—Ä—É–∂–µ–Ω–∞: /path/to/pretrained_lora.safetensors
üîó –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –¥–æ–æ–±—É—á–µ–Ω–∏–µ —Å –≥–æ—Ç–æ–≤–æ–π LoRA: /path/to/pretrained_lora.safetensors
‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è LoRA –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞

üöÄ –ó–∞–ø—É—Å–∫ –¥–æ–æ–±—É—á–µ–Ω–∏—è –≥–æ—Ç–æ–≤–æ–π LoRA
   üìÅ –ò—Å—Ö–æ–¥–Ω–∞—è LoRA: /path/to/pretrained_lora.safetensors
   üéØ –ù–æ–≤—ã–π —Ç—Ä–∏–≥–≥–µ—Ä: NEWSTYLE
   üìä –®–∞–≥–æ–≤ –æ–±—É—á–µ–Ω–∏—è: 500
   üìà Learning rate: 2e-4

...

üéâ –î–æ–æ–±—É—á–µ–Ω–∏–µ LoRA –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!
   üìÅ –ò—Å—Ö–æ–¥–Ω–∞—è LoRA: https://huggingface.co/user/model/resolve/main/lora.safetensors
   ‚ú® –†–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∞—è LoRA: 15.2 MB
   üéØ –¢—Ä–∏–≥–≥–µ—Ä-—Å–ª–æ–≤–æ: NEWSTYLE
   üìä –í—ã–ø–æ–ª–Ω–µ–Ω–æ —à–∞–≥–æ–≤: 500
```

## Weights & Biases –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è

–ü—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ W&B, –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–æ–æ–±—É—á–µ–Ω–∏–∏ –±—É–¥–µ—Ç –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å—Å—è:
- `pretrained_lora_url` - URL –∏—Å—Ö–æ–¥–Ω–æ–π LoRA
- `is_fine_tuning_mode` - —Ñ–ª–∞–≥ —Ä–µ–∂–∏–º–∞ –¥–æ–æ–±—É—á–µ–Ω–∏—è
- `keep_optimizer_for_resume` - —Å–æ—Ö—Ä–∞–Ω–µ–Ω –ª–∏ optimizer

## –í–∞–∂–Ω—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è

1. **–§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–æ–≤**: –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ `.safetensors` —Ñ–∞–π–ª—ã
2. **–ò—Å—Ç–æ—á–Ω–∏–∫–∏**: –¢–æ–ª—å–∫–æ HuggingFace URLs –≤ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç
3. **–ö–æ–Ω—Ñ–ª–∏–∫—Ç—ã**: –ù–µ–ª—å–∑—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `pretrained_lora_url` –∏ `skip_training_and_use_pretrained_hf_lora_url`
4. **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã**: –ú–æ–∂–Ω–æ –∏–∑–º–µ–Ω—è—Ç—å –ª—é–±—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è (learning rate, steps, trigger word –∏ —Ç.–¥.)
5. **–ü–∞–º—è—Ç—å**: –î–æ–æ–±—É—á–µ–Ω–∏–µ —Ç—Ä–µ–±—É–µ—Ç —Å—Ç–æ–ª—å–∫–æ –∂–µ –ø–∞–º—è—Ç–∏, —Å–∫–æ–ª—å–∫–æ –æ–±—ã—á–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ

## –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏

- –ì–æ—Ç–æ–≤–∞—è LoRA –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –æ–±—É—á–µ–Ω–∏—è
- –í–µ—Å–∞ LoRA –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–æ–≤–æ–π —Å–µ—Ç–∏
- –≠—Ç–æ **–Ω–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ**, –∞ –Ω–µ resume –ø—Ä–µ—Ä–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞
- Optimizer –∏ scheduler –Ω–∞—á–∏–Ω–∞—é—Ç —Å –Ω—É–ª—è
- –í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è –º–æ–≥—É—Ç –±—ã—Ç—å –∏–∑–º–µ–Ω–µ–Ω—ã

–£–¥–∞—á–Ω–æ–≥–æ –¥–æ–æ–±—É—á–µ–Ω–∏—è! üöÄ 